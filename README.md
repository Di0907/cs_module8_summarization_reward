# Module 8 â€“ Summarization with Expert Models & Reward Modeling

This repository contains the full implementation for **Module 8**, which focuses on building a high-quality summarization pipeline using expert models, human preference learning, and reward-based evaluation.

---

## ğŸ“Œ Project Overview

The goal of this project is to:

- Build a robust **summarization pipeline** for technical papers
- Generate alternative summaries (Summary A vs. Summary B)
- Collect **human preferences**
- Fine-tune a **DeBERTa-v3 reward model**
- Rank and score summaries based on learned quality signals

The pipeline demonstrates **human-in-the-loop evaluation**, **reward modeling**, and **modular model routing**.

---

## ğŸ§± Repository Structure
```text
cs_module8_summarization_reward/
â”œâ”€ data/ # Input data and human preferences
â”‚ â””â”€ preferences.csv
â”œâ”€ outputs/ # Generated summaries and evaluation results
â”‚ â”œâ”€ summaries.jsonl
â”‚ â”œâ”€ summaries_ab.json
â”‚ â”œâ”€ summaries_for_scoring.jsonl
â”‚ â”œâ”€ summary_results.csv
â”‚ â””â”€ reward_model/ # (ignored) trained reward model artifacts
â”œâ”€ scripts/ # Pipeline scripts
â”‚ â”œâ”€ extract_text.py
â”‚ â”œâ”€ summarize.py
â”‚ â”œâ”€ generate_summaries.py
â”‚ â”œâ”€ make_preferences.py
â”‚ â”œâ”€ prepare_preferences.py
â”‚ â”œâ”€ train_reward_model.py
â”‚ â””â”€ score_summaries.py
â”œâ”€ report/
â”‚ â””â”€ Evaluation_Report.md # Evaluation & model routing explanation
â”œâ”€ requirements.txt
â””â”€ README.md
```
---
## How to Run

1. Install dependencies:
pip install -r requirements.txt

2. Run the pipeline scripts in order:
python scripts/extract_text.py
python scripts/generate_summaries.py
python scripts/make_preferences.py
python scripts/train_reward_model.py
python scripts/score_summaries.py
---
## Deliverables Checklist

Summarization pipeline code âœ…

Trained reward model (artifacts excluded due to size) âœ…

Summary quality scores (summary_results.csv) âœ…

Evaluation report âœ…

---

## Questions

How does preference-based evaluation compare to automatic metrics?

How does reward modeling improve summary quality ranking?

How can multimodal inputs further enhance summarization performance?

---
## Primary Reviewer
Primary Reviewer: Scott Lai

---

## ğŸ” Pipeline Workflow

### 1. Text Extraction
- Extract paper text from PDF files

### 2. Summary Generation
- Generate two candidate summaries (A/B) per paper
- Large language model used for technical summarization

### 3. Human Preference Collection
- Human preferences collected for each summary pair
- Stored in `data/preferences.csv`

### 4. Reward Model Training
- Fine-tune a **DeBERTa-v3** model using preference pairs
- The reward model learns to predict which summary is preferred

### 5. Summary Scoring
- Each summary is scored by the trained reward model
- Final rankings saved in `outputs/summary_results.csv`

---

## ğŸ“Š Evaluation

### Evaluation Metrics
- **Preference-based reward modeling** (primary)
- Conceptual discussion of:
  - ROUGE
  - BERTScore

Detailed evaluation methodology is documented in:
report/Evaluation_Report.md

---

## ğŸ§  Multimodal & Model Routing

The pipeline supports **modular expert models**:

| Stage | Model |
|------|------|
| Text + figure understanding | DeepSeek-VL |
| Summary generation | Mixtral 8x22B |
| Quality evaluation | DeBERTa-v3 reward model |

Routing decisions are based on input type and task stage.

---

## ğŸ“ Outputs

- `summary_results.csv` contains:
  - Reward scores for Summary A and Summary B
  - Final preferred summary per paper
- Results cover **10 technical papers**, as required

---

## âš ï¸ Notes on Large Files

Trained reward model weights (e.g., `model.safetensors`) are **not tracked in GitHub** due to GitHubâ€™s file size limits.

All training scripts and configurations are provided to ensure reproducibility.

---

## ğŸ“¦ Dependencies

Key dependencies are listed in:

requirements.txt

---

## âœ… Status

âœ” Summarization pipeline implemented  
âœ” Human preferences collected  
âœ” Reward model trained  
âœ” Quality-scored summaries generated  
âœ” Evaluation and routing documented  

This repository fully satisfies the **Module 8 project requirements**.

